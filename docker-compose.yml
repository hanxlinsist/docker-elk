version: '3.2'

services:
  elasticsearch:
    build:
      context: ./elasticsearch  # Either a path to a directory containing a Dockerfile, or a url to a git repository
      args:  # Add build arguments, which are environment variables accessible only during the build process
      ELK_VERSION: $ELK_VERSION # 你在 Dockerfile 中定义的参数（比如 ARG ELK_VERSION）可以访问到这个值
    logging:
      driver: json-file
      options:  
         max-size: "10m"  # 类似于 log4j2，设置日志滚动策略的
         max-file: "10"
    volumes:
      # - type: bind
      #   source: ./elasticsearch/config/elasticsearch.yml
      #   target: /usr/share/elasticsearch/config/elasticsearch.yml
      #   read_only: true
      - type: volume
        source: elasticsearch
        target: /usr/share/elasticsearch/data
    ports:
      - "9200:9200"  #  HOST:CONTAINER
    environment:  # 容器运行时内部的环境变量，如果只指定 key，没有指定 value，它会找宿主机对应环境变量的值，which can be helpful for secret or host-specific values
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
      ELASTIC_PASSWORD: changeme
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk
  
  logstash:
    build:
      context: ./logstash
      args:
        ELK_VERSION: $ELK_VERSION
    logging:
      driver: json-file
      options:  
        max-size: "10m"  # 类似于 log4j2，设置日志滚动策略的
        max-file: "10"
    volumes:
      # - type: bind
      #   source: ./logstash/config/logstash.yml
      #   target: /usr/share/logstash/config/logstash.yml
      #   read_only: true
      - type: bind
        source: ./logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - elk
    depends_on:   # 参考印象笔记：Docker 网络
      - elasticsearch
      
  kibana:
    build:
      context: ./kibana
      args:
        ELK_VERSION: $ELK_VERSION
    logging:
      driver: json-file
      options:  
         max-size: "10m"  # 类似于 log4j2，设置日志滚动策略的
         max-file: "10"
   #  volumes:
   #    - type: bind
   #      source: ./kibana/config/kibana.yml
   #      target: /usr/share/kibana/config/kibana.yml
   #      read_only: true
    ports:
      - "5601:5601"
    networks:
      - elk
    depends_on:
      - elasticsearch

networks:
  elk:
    driver: bridge

volumes:
  elasticsearch: